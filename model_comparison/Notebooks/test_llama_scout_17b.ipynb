{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Llama Scout 17B for ASL Recognition\n",
    "\n",
    "This notebook tests the Llama Scout 17B model for ASL sign language recognition using IBM WatsonX platform.\n",
    "\n",
    "The notebook includes:\n",
    "- Setting up environment and authentication\n",
    "- Image processing and encoding\n",
    "- Multiple prompting strategies\n",
    "- API request handling with retries\n",
    "- Result parsing and evaluation\n",
    "\n",
    "### Note: This notebook requires WatsonX API credentials in the backend/.env file\n",
    "### Please refer to test_llama_90b_vision.py for the actually implemented script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import base64\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "import io\n",
    "import time\n",
    "import re\n",
    "import argparse\n",
    "from typing import Dict, Any, List, Literal\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "from io import BytesIO\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Environment Variables\n",
    "\n",
    "Load the WatsonX API credentials from the environment variables file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading .env file from: /Users/henrikjacobsen/Desktop/CBS/Semester 2/Artifical Intelligence and Machine Learning/Final Project/AIML25-shared/backend/.env\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from backend/.env\n",
    "dotenv_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))), 'backend', '.env')\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "print(f\"Loading .env file from: {dotenv_path}\")\n",
    "\n",
    "# Get WatsonX credentials\n",
    "WATSONX_API_KEY = os.getenv(\"WATSONX_API_KEY\")\n",
    "WATSONX_PROJECT_ID = os.getenv(\"WATSONX_PROJECT_ID\")\n",
    "WATSONX_URL = os.getenv(\"WATSONX_URL\", \"https://us-south.ml.cloud.ibm.com\")\n",
    "\n",
    "if not all([WATSONX_API_KEY, WATSONX_PROJECT_ID]):\n",
    "    raise ValueError(\"WatsonX credentials not found in environment variables. Please check your .env file.\")\n",
    "\n",
    "# Model ID\n",
    "MODEL_ID = \"meta-llama/llama-4-scout-17b-16e-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Prompt Templates\n",
    "\n",
    "Different prompting strategies for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt templates\n",
    "PROMPT_TEMPLATES = {\n",
    "\"zero_shot\": \"\"\"You are an expert in American Sign Language (ASL) recognition. Analyze the provided image and identify the ASL letter being signed (A-Z).\n",
    "\n",
    "Respond only with a valid JSON object, using this format:\n",
    "{\n",
    "  \"letter\": \"A single uppercase letter (A-Z)\",\n",
    "  \"confidence\": \"confidence score (0-1)\",\n",
    "  \"feedback\": \"A short explanation of how the gesture maps to the predicted letter\"\n",
    "}\n",
    "Be precise and avoid adding anything outside the JSON response.\"\"\",\n",
    "\n",
    "\"few_shot\": \"\"\"You are an expert in American Sign Language (ASL) recognition. Analyze the provided image and identify the ASL letter being signed (A-Z).\n",
    "\n",
    "Here are some known ASL hand signs:\n",
    "- A: Fist with thumb resting on the side\n",
    "- B: Flat open hand, fingers extended upward, thumb across the palm\n",
    "- C: Hand curved into the shape of the letter C\n",
    "- D: Index finger up, thumb touching middle finger forming an oval\n",
    "- E: Fingers bent, thumb tucked under\n",
    "\n",
    "Respond only with a JSON object like this:\n",
    "{\n",
    "  \"letter\": \"A single uppercase letter (A-Z)\",\n",
    "  \"confidence\": \"confidence score (0-1)\",\n",
    "  \"feedback\": \"Why this gesture matches the predicted letter\"\n",
    "}\n",
    "Only return the JSON object. No explanations before or after.\"\"\",\n",
    "\n",
    "\"chain_of_thought\": \"\"\"You are an expert in American Sign Language (ASL) recognition. Carefully analyze the provided image step-by-step to identify the ASL letter (A-Z).\n",
    "\n",
    "1. Describe the hand shape\n",
    "2. Describe the finger and thumb positions\n",
    "3. Compare these to known ASL letter signs\n",
    "4. Identify the most likely letter\n",
    "\n",
    "Then output your answer as JSON:\n",
    "{\n",
    "  \"letter\": \"A single uppercase letter (A-Z)\",\n",
    "  \"confidence\": \"confidence score (0-1),\n",
    "  \"feedback\": \"Summarize your reasoning in one sentence\"\n",
    "}\n",
    "Return only the JSON object with no extra text.\"\"\",\n",
    "\n",
    "\"visual_grounding\": \"\"\"You are an expert in American Sign Language (ASL) recognition. Carefully analyze the provided image of a hand gesture and determine which ASL letter (A–Z) it represents.\n",
    "\n",
    "To guide your analysis, consider the following:\n",
    "- Which fingers are extended or bent?\n",
    "- Is the thumb visible, and where is it positioned?\n",
    "- What is the orientation of the palm (facing forward, sideways, etc.)?\n",
    "- Are there any unique shapes formed (e.g., circles, fists, curves)?\n",
    "\n",
    "Now, based on this visual inspection, provide your prediction in the following JSON format:\n",
    "\n",
    "{\n",
    "  \"letter\": \"predicted letter (A-Z)\",\n",
    "  \"confidence\": \"confidence score (0–1)\",\n",
    "  \"feedback\": \"brief explanation describing the observed hand shape and reasoning\"\n",
    "}\n",
    "\n",
    "Be precise, use visual clues from the image, and avoid guessing without justification.\"\"\",\n",
    "\n",
    "\"contrastive\": \"\"\"You are an expert in American Sign Language (ASL) recognition. Analyze the provided image of a hand gesture and identify the correct ASL letter.\n",
    "\n",
    "Consider the following candidate letters: A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z\n",
    "(These letters are visually similar and often confused.)\n",
    "\n",
    "Step-by-step:\n",
    "1. Observe the hand shape, finger positions, and thumb placement.\n",
    "2. Compare the observed gesture against the typical signs for each candidate letter.\n",
    "3. Eliminate unlikely candidates based on visible differences.\n",
    "4. Choose the most plausible letter and explain your reasoning.\n",
    "\n",
    "Format your response as JSON:\n",
    "\n",
    "{\n",
    "  \"letter\": \"predicted letter from candidates\",\n",
    "  \"confidence\": \"confidence score (0–1)\",\n",
    "  \"feedback\": \"why this letter was selected over the others\"\n",
    "}\n",
    "\n",
    "Be analytical and compare carefully to avoid misclassification.\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "Helper functions for token estimation, authentication, and image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_tokens(text: str) -> int:\n",
    "    \"\"\"Estimate the number of tokens in a text string (1 token ≈ 4 characters).\"\"\"\n",
    "    return len(text) // 4\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "def get_watsonx_token(api_key: str) -> str:\n",
    "    \"\"\"Get a token for WatsonX API authentication with retry logic.\"\"\"\n",
    "    auth_url = \"https://iam.cloud.ibm.com/identity/token\"\n",
    "    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "    data = {\"grant_type\": \"urn:ibm:params:oauth:grant-type:apikey\", \"apikey\": api_key}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(auth_url, headers=headers, data=data)\n",
    "        response.raise_for_status()\n",
    "        return response.json().get(\"access_token\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error getting WatsonX token: {e}\")\n",
    "        raise\n",
    "\n",
    "def encode_image_base64(image_path):\n",
    "    \"\"\"Encode image to base64 string with proper format for Llama Scout.\"\"\"\n",
    "    try:\n",
    "        # Open and convert to RGB\n",
    "        with Image.open(image_path) as img:\n",
    "            # Convert to RGB if needed\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Get original dimensions\n",
    "            logging.info(f\"Original image dimensions: {img.size}\")\n",
    "            \n",
    "            # Resize to smaller dimensions\n",
    "            new_size = (512, 512)\n",
    "            img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "            logging.info(f\"Resized image dimensions: {img.size}\")\n",
    "            \n",
    "            # Save to bytes with JPEG format\n",
    "            buffer = io.BytesIO()\n",
    "            img.save(buffer, format=\"JPEG\", quality=95)\n",
    "            buffer.seek(0)\n",
    "            \n",
    "            # Get buffer size\n",
    "            buffer_size = len(buffer.getvalue())\n",
    "            logging.info(f\"Buffer size before base64: {buffer_size} bytes\")\n",
    "            \n",
    "            # Encode to base64\n",
    "            img_str = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "            logging.info(f\"Base64 string length: {len(img_str)}\")\n",
    "            \n",
    "            return img_str\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error encoding image: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "def make_api_request(token: str, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Make API request with retry logic.\"\"\"\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {token}\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{WATSONX_URL}/ml/v1/text/chat?version=2023-05-29\",\n",
    "            headers=headers,\n",
    "            json=payload,\n",
    "            timeout=60\n",
    "        )\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            logging.error(f\"API Error Response: {response.text}\")\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        logging.error(f\"HTTP Error: {str(e)}\")\n",
    "        if hasattr(e.response, 'text'):\n",
    "            logging.error(f\"Error Response: {e.response.text}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"API Request Error: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Prediction Function\n",
    "\n",
    "Function to get ASL predictions from the Llama Scout 17B model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_asl_prediction(image_path: str, strategy: str = \"zero_shot\") -> dict:\n",
    "    \"\"\"Get ASL prediction from Llama Scout model.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        token = get_watsonx_token(WATSONX_API_KEY)\n",
    "        if not token:\n",
    "            return {\n",
    "                \"error\": \"Failed to get authentication token\",\n",
    "                \"metadata\": {\n",
    "                    \"response_time\": round(time.time() - start_time, 3),\n",
    "                    \"model\": \"llama_scout_17b\",\n",
    "                    \"strategy\": strategy\n",
    "                }\n",
    "            }\n",
    "\n",
    "        # Process image and get data URI\n",
    "        image_data_uri = encode_image_base64(image_path)\n",
    "\n",
    "        # Get the appropriate prompt template\n",
    "        prompt_template = PROMPT_TEMPLATES.get(strategy, PROMPT_TEMPLATES[\"zero_shot\"])\n",
    "\n",
    "        # Create the payload with the actual ASL prediction request\n",
    "        payload = {\n",
    "            \"model_id\": MODEL_ID,\n",
    "            \"project_id\": WATSONX_PROJECT_ID,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are an expert in American Sign Language (ASL) recognition. Analyze the provided image and identify the ASL letter being signed (A-Z).\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt_template\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{image_data_uri}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": 0.05,\n",
    "            \"top_p\": 1.0,\n",
    "            \"max_tokens\": 300\n",
    "        }\n",
    "        \n",
    "        result = make_api_request(token, payload)\n",
    "        \n",
    "        # Extract the generated text\n",
    "        generated_text = result.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "        \n",
    "        # Clean the response text - remove any markdown code blocks\n",
    "        generated_text = generated_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        \n",
    "        # Parse the JSON response\n",
    "        try:\n",
    "            prediction = json.loads(generated_text)\n",
    "            if not isinstance(prediction, dict):\n",
    "                raise ValueError(\"Response is not a valid JSON object\")\n",
    "            \n",
    "            if \"letter\" not in prediction:\n",
    "                raise ValueError(\"Response missing 'letter' field\")\n",
    "\n",
    "            # Calculate response time\n",
    "            response_time = time.time() - start_time\n",
    "            \n",
    "            # Return the prediction in the format expected by evaluate_models.py\n",
    "            return {\n",
    "                \"letter\": prediction[\"letter\"],\n",
    "                \"confidence\": prediction.get(\"confidence\", 0.0),\n",
    "                \"feedback\": prediction.get(\"feedback\", \"\"),\n",
    "                \"metadata\": {\n",
    "                    \"response_time\": round(response_time, 3),\n",
    "                    \"model\": \"llama_scout_17b\",\n",
    "                    \"strategy\": strategy\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.error(f\"Failed to parse JSON response: {e}\")\n",
    "            logging.error(f\"Raw response: {generated_text}\")\n",
    "            return {\n",
    "                \"error\": \"Invalid JSON response from model\",\n",
    "                \"raw_response\": generated_text,\n",
    "                \"metadata\": {\n",
    "                    \"response_time\": round(time.time() - start_time, 3),\n",
    "                    \"model\": \"llama_scout_17b\",\n",
    "                    \"strategy\": strategy\n",
    "                }\n",
    "            }\n",
    "        except ValueError as e:\n",
    "            logging.error(f\"Invalid response format: {e}\")\n",
    "            return {\n",
    "                \"error\": str(e),\n",
    "                \"metadata\": {\n",
    "                    \"response_time\": round(time.time() - start_time, 3),\n",
    "                    \"model\": \"llama_scout_17b\",\n",
    "                    \"strategy\": strategy\n",
    "                }\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        response_time = time.time() - start_time\n",
    "        logging.error(f\"Error in ASL prediction: {e}\")\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"metadata\": {\n",
    "                \"response_time\": round(response_time, 3),\n",
    "                \"model\": \"llama_scout_17b\",\n",
    "                \"strategy\": strategy\n",
    "            }\n",
    "        }\n",
    "    finally:\n",
    "        # Add a delay to respect rate limits\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "Run a test prediction with the model on a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Llama Scout 17B model with zero_shot strategy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 12:09:47,770 - INFO - Original image dimensions: (1280, 720)\n",
      "2025-05-13 12:09:47,799 - INFO - Resized image dimensions: (512, 512)\n",
      "2025-05-13 12:09:47,804 - INFO - Buffer size before base64: 57420 bytes\n",
      "2025-05-13 12:09:47,806 - INFO - Base64 string length: 76560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Llama Scout 17B zero_shot result:\n",
      "{\n",
      "  \"letter\": \"V\",\n",
      "  \"confidence\": 0.9,\n",
      "  \"feedback\": \"The signer is extending the index and middle fingers while tucking the other fingers into the palm, which corresponds to the ASL letter 'V'.\",\n",
      "  \"metadata\": {\n",
      "    \"response_time\": 1.727,\n",
      "    \"model\": \"llama_scout_17b\",\n",
      "    \"strategy\": \"zero_shot\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Define a path to test image\n",
    "image_path = \"/Users/henrikjacobsen/Desktop/CBS/Semester 2/Artifical Intelligence and Machine Learning/Final Project/AIML25-shared/model_comparison/data/V/V_17_20250428_114126.jpg\"\n",
    "strategy = \"zero_shot\"\n",
    "\n",
    "# Check if the image exists\n",
    "if not os.path.exists(image_path):\n",
    "    print(f\"Image file not found: {image_path}\")\n",
    "else:\n",
    "    # Run prediction\n",
    "    print(f\"Testing Llama Scout 17B model with {strategy} strategy...\")\n",
    "    result = get_asl_prediction(image_path, strategy)\n",
    "    print(f\"\\nLlama Scout 17B {strategy} result:\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "    \n",
    "    # Save the result to a file\n",
    "    timestamp = int(time.time())\n",
    "    results_file = f\"llama_scout_17b_{strategy}_result_{timestamp}.json\"\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(result, f, indent=2)\n",
    "    print(f\"\\nResult saved to {results_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
