{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f7ba956",
   "metadata": {},
   "source": [
    "**INTRO TO HOW YOU USE THIS:**\n",
    "1. WHEN YOU RUN THE SCRIPT IT WILL OPEN AN EXTERNAL CAMERA WINDOW â€“ THIS IS WHAT WE ARE USING TO LOG THE DATA.\n",
    "2. IF YOU WISH TO ENTER LOGGING MODE (WHERE YOU CAN COLLECT THE DATAPOINTS FOR THE HANDSIGN YOU'RE MAKING) PRESS \"1\"\n",
    "3. MAKE THE HAND SIGN YOU WANT AND PRESS THE CORRESPONDING KEY ON THE KEYBOARD AND IT WILL BE LOGGED (A MESSAGE WILL APPEAR BRIEFLY INDICATING WHAT LETTER YOU PRESSED)\n",
    "4. TO EXIT LOGGING MODE, PRESS \"0\"\n",
    "5. TO EXIT THE PROGRAM ALTOGETHER, PRESS \"ESC\"\n",
    "\n",
    "_A note on how the data is structured in the .csv: Each row represents one logged hand signal. That is, when you have the program open in logging mode and click a possible button. The following 42 columns are the respective X and Y 'coordinates' of each segment of the hand. The first two columns are always 0,0 as these are the palm node from which the relative position of all the other segments is calculated. While this may seem odd, it makes a lot more sense to calculate the finger position relatively as opposed to where they appear pixel wise in the image, as this is prone to change and would make the model very rigid and overiftting._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eb3cb0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow, mediapipe, opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3853dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0d9674f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"class KeyPointClassifier(object):\\n    def __init__(\\n        self,\\n        model_path='./data/keypoint_classifier.pt',\\n        num_threads=1,\\n    ):\\n        self.interpreter = tf.lite.Interpreter(model_path=model_path,\\n                                               num_threads=num_threads)\\n\\n        self.interpreter.allocate_tensors()\\n        self.input_details = self.interpreter.get_input_details()\\n        self.output_details = self.interpreter.get_output_details()\\n\\n    def __call__(\\n        self,\\n        landmark_list,\\n    ):\\n        input_details_tensor_index = self.input_details[0]['index']\\n        self.interpreter.set_tensor(\\n            input_details_tensor_index,\\n            np.array([landmark_list], dtype=np.float32))\\n        self.interpreter.invoke()\\n\\n        output_details_tensor_index = self.output_details[0]['index']\\n\\n        result = self.interpreter.get_tensor(output_details_tensor_index)\\n\\n        result_index = np.argmax(np.squeeze(result))\\n\\n        return result_index\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''class KeyPointClassifier(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path='./data/keypoint_classifier.pt',\n",
    "        num_threads=1,\n",
    "    ):\n",
    "        self.interpreter = tf.lite.Interpreter(model_path=model_path,\n",
    "                                               num_threads=num_threads)\n",
    "\n",
    "        self.interpreter.allocate_tensors()\n",
    "        self.input_details = self.interpreter.get_input_details()\n",
    "        self.output_details = self.interpreter.get_output_details()\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        landmark_list,\n",
    "    ):\n",
    "        input_details_tensor_index = self.input_details[0]['index']\n",
    "        self.interpreter.set_tensor(\n",
    "            input_details_tensor_index,\n",
    "            np.array([landmark_list], dtype=np.float32))\n",
    "        self.interpreter.invoke()\n",
    "\n",
    "        output_details_tensor_index = self.output_details[0]['index']\n",
    "\n",
    "        result = self.interpreter.get_tensor(output_details_tensor_index)\n",
    "\n",
    "        result_index = np.argmax(np.squeeze(result))\n",
    "\n",
    "        return result_index'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a6eaadd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyPointClassifier:\n",
    "    def __init__(self, model_path='./data/keypoint_classifier.pt'):\n",
    "        # Load the PyTorch model\n",
    "        self.model = torch.jit.load(model_path)\n",
    "        self.model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    def __call__(self, landmark_list):\n",
    "        # Convert the input landmark list to a PyTorch tensor\n",
    "        input_tensor = torch.tensor([landmark_list], dtype=torch.float32)\n",
    "\n",
    "        # Perform inference\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_tensor)\n",
    "\n",
    "        # Get the predicted class index\n",
    "        result_index = torch.argmax(output, dim=1).item()\n",
    "        return result_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "82d71e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744837717.615460 4424501 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1 Pro\n",
      "W0000 00:00:1744837717.625013 4683994 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1744837717.629914 4683994 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    cap_device = 0\n",
    "    cap_width = 960\n",
    "    cap_height = 540\n",
    "\n",
    "    use_brect = True\n",
    "\n",
    "    cap = cv.VideoCapture(cap_device)\n",
    "    cap.set(cv.CAP_PROP_FRAME_WIDTH, cap_width)\n",
    "    cap.set(cv.CAP_PROP_FRAME_HEIGHT, cap_height)\n",
    "\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(\n",
    "        model_complexity=0,\n",
    "        static_image_mode=True,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.7\n",
    "    )\n",
    "\n",
    "    keypoint_classifier = KeyPointClassifier()\n",
    "\n",
    "    with open('./data/keypoint_classifier_labels.csv', encoding='utf-8-sig') as f:\n",
    "        keypoint_classifier_labels = csv.reader(f)\n",
    "        keypoint_classifier_labels = [row[0] for row in keypoint_classifier_labels]\n",
    "\n",
    "    mode = 0\n",
    "\n",
    "    while True:\n",
    "        key = cv.waitKey(10)\n",
    "        if key == 27:\n",
    "            break\n",
    "        if key != -1:\n",
    "            print()\n",
    "        number, mode = select_mode(key, mode)\n",
    "\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        image = cv.flip(image, 1)\n",
    "        debug_image = copy.deepcopy(image)\n",
    "\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        if results.multi_hand_landmarks is not None:\n",
    "            for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "                brect = calc_bounding_rect(debug_image, hand_landmarks)\n",
    "                landmark_list = calc_landmark_list(debug_image, hand_landmarks)\n",
    "\n",
    "                pre_processed_landmark_list = pre_process_landmark(landmark_list)\n",
    "\n",
    "                logging_csv(number, mode, pre_processed_landmark_list)\n",
    "\n",
    "                hand_sign_id = keypoint_classifier(pre_processed_landmark_list)\n",
    "\n",
    "                debug_image = draw_bounding_rect(use_brect, debug_image, brect)\n",
    "                debug_image = draw_landmarks(debug_image, landmark_list)\n",
    "                debug_image = draw_info_text(\n",
    "                    debug_image,\n",
    "                    brect,\n",
    "                    handedness,\n",
    "                    keypoint_classifier_labels[hand_sign_id],\n",
    "                    \"\"\n",
    "                )\n",
    "\n",
    "        debug_image = draw_info(debug_image, mode, number)\n",
    "\n",
    "        cv.imshow('Hand Gesture Recognition', debug_image)\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "def logging_csv(number, mode, landmark_list):\n",
    "    \"\"\"\n",
    "    Logs the selected number and landmark list to a CSV file if mode is 1.\n",
    "    Also logs a horizontally mirrored version of the landmarks and introduces variance.\n",
    "    \"\"\"\n",
    "    if mode == 0:\n",
    "        # Mode 0: No logging\n",
    "        pass\n",
    "    elif mode == 1 and (0 <= number <= 25):  # Ensure number corresponds to A-Z (0-25)\n",
    "        csv_path = './data/keypoint.csv'\n",
    "        try:\n",
    "            with open(csv_path, 'a', newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                \n",
    "                # Log the original data\n",
    "                writer.writerow([chr(number + 97), *landmark_list])\n",
    "                \n",
    "                # Create and log the mirrored data\n",
    "                mirrored_landmark_list = mirror_landmarks(landmark_list)\n",
    "                writer.writerow([chr(number + 97), *mirrored_landmark_list])\n",
    "                \n",
    "                # Add variance to the original data and log it\n",
    "                varied_landmark_list = add_variance(landmark_list)\n",
    "                writer.writerow([chr(number + 97), *varied_landmark_list])\n",
    "                \n",
    "                # Add variance to the mirrored data and log it\n",
    "                varied_mirrored_landmark_list = add_variance(mirrored_landmark_list)\n",
    "                writer.writerow([chr(number + 97), *varied_mirrored_landmark_list])\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: CSV path '{csv_path}' not found.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while logging to CSV: {e}\")\n",
    "    return\n",
    "\n",
    "def mirror_landmarks(landmark_list):\n",
    "    \"\"\"\n",
    "    Mirrors the landmarks horizontally by flipping the x-coordinates.\n",
    "    Assumes the x-coordinates are in even indices and y-coordinates in odd indices.\n",
    "    \"\"\"\n",
    "    mirrored_landmark_list = []\n",
    "    for i in range(0, len(landmark_list), 2):\n",
    "        x = landmark_list[i]\n",
    "        y = landmark_list[i + 1]\n",
    "        mirrored_x = -x  # Flip the x-coordinate\n",
    "        mirrored_landmark_list.extend([mirrored_x, y])\n",
    "    return mirrored_landmark_list\n",
    "\n",
    "def add_variance(landmark_list, variance=0.02):\n",
    "    \"\"\"\n",
    "    Adds random variance to the landmark coordinates.\n",
    "    The variance is applied as a small random offset to each coordinate.\n",
    "    \"\"\"\n",
    "    varied_landmark_list = []\n",
    "    for coord in landmark_list:\n",
    "        varied_coord = coord + random.uniform(-variance, variance)\n",
    "        varied_landmark_list.append(varied_coord)\n",
    "    return varied_landmark_list\n",
    "\n",
    "def select_mode(key, mode):\n",
    "    number = -1\n",
    "    if ord('a') <= key <= ord('z'):  # A ~ Z\n",
    "        number = key - 97  # Map ASCII A-Z to 0-25\n",
    "    elif key == ord('0'):  # '0' key\n",
    "        mode = 0 # nothing mode\n",
    "    elif key == ord('1'):  # '1' key \n",
    "        mode = 1 # logging mode\n",
    "    return number, mode\n",
    "\n",
    "def pre_process_landmark(landmark_list):\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_landmark_list = list(\n",
    "        itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    # Normalization\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / max_value\n",
    "\n",
    "    temp_landmark_list = list(map(normalize_, temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list\n",
    "\n",
    "def draw_landmarks(image, landmark_point):\n",
    "    def draw_line_pair(p1, p2):\n",
    "        cv.line(image, tuple(p1), tuple(p2), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(p1), tuple(p2), (255, 255, 255), 2)\n",
    "\n",
    "    def draw_keypoint(pt, radius):\n",
    "        cv.circle(image, tuple(pt), radius, (255, 255, 255), -1)\n",
    "        cv.circle(image, tuple(pt), radius, (0, 0, 0), 1)\n",
    "\n",
    "    if len(landmark_point) > 0:\n",
    "        # Fingers\n",
    "        finger_connections = [\n",
    "            [2, 3, 4],     # Thumb\n",
    "            [5, 6, 7, 8],  # Index\n",
    "            [9, 10, 11, 12],  # Middle\n",
    "            [13, 14, 15, 16],  # Ring\n",
    "            [17, 18, 19, 20]   # Pinky\n",
    "        ]\n",
    "        for finger in finger_connections:\n",
    "            for i in range(len(finger) - 1):\n",
    "                draw_line_pair(landmark_point[finger[i]], landmark_point[finger[i + 1]])\n",
    "\n",
    "        # Palm\n",
    "        palm_connections = [\n",
    "            (0, 1), (1, 2), (2, 5), (5, 9),\n",
    "            (9, 13), (13, 17), (17, 0)\n",
    "        ]\n",
    "        for start, end in palm_connections:\n",
    "            draw_line_pair(landmark_point[start], landmark_point[end])\n",
    "\n",
    "    # Key points\n",
    "    for index, landmark in enumerate(landmark_point):\n",
    "        if index in [4, 8, 12, 16, 20]:  # Fingertips\n",
    "            draw_keypoint(landmark, 8)\n",
    "        else:\n",
    "            draw_keypoint(landmark, 5)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_bounding_rect(use_brect, image, brect):\n",
    "    if use_brect:\n",
    "        # Outer rectangle\n",
    "        cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]),\n",
    "                     (0, 0, 0), 1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_info_text(image, brect, handedness, hand_sign_text,\n",
    "                   finger_gesture_text):\n",
    "    cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[1] - 22),\n",
    "                 (0, 0, 0), -1)\n",
    "\n",
    "    info_text = handedness.classification[0].label[0:]\n",
    "    if hand_sign_text != \"\":\n",
    "        info_text = info_text + ':' + hand_sign_text\n",
    "    cv.putText(image, info_text, (brect[0] + 5, brect[1] - 4),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv.LINE_AA)\n",
    "\n",
    "    if finger_gesture_text != \"\":\n",
    "        cv.putText(image, \"Finger Gesture:\" + finger_gesture_text, (10, 60),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 4, cv.LINE_AA)\n",
    "        cv.putText(image, \"Finger Gesture:\" + finger_gesture_text, (10, 60),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2,\n",
    "                   cv.LINE_AA)\n",
    "\n",
    "    return image\n",
    "\n",
    "def calc_bounding_rect(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_array = np.empty((0, 2), int)\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "\n",
    "        landmark_point = [np.array((landmark_x, landmark_y))]\n",
    "\n",
    "        landmark_array = np.append(landmark_array, landmark_point, axis=0)\n",
    "\n",
    "    x, y, w, h = cv.boundingRect(landmark_array)\n",
    "\n",
    "    return [x, y, x + w, y + h]\n",
    "\n",
    "def calc_landmark_list(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "\n",
    "    # Keypoint\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_point\n",
    "\n",
    "def draw_info(image, mode, number):\n",
    "    mode_string = ['Logging Key Point', 'Not Logging']\n",
    "    if 1 <= mode <= 2:\n",
    "        cv.putText(image, \"MODE: \" + mode_string[mode - 1], (10, 90),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                   cv.LINE_AA)\n",
    "        if number == -1:\n",
    "            pass\n",
    "        elif 0 <= number <= 25:\n",
    "            cv.putText(image, \"LETTER: \" + str(chr(number+97)), (10, 110),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                       cv.LINE_AA)\n",
    "    return image\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9a19ec",
   "metadata": {},
   "source": [
    "The below code introduces the direction the hand is pointing instead of only relative position of the fingers, this is important to be able to distinguish signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aa3a13ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import csv\\nimport copy\\nimport random\\n\\nimport cv2 as cv\\nimport numpy as np\\nimport mediapipe as mp\\nimport torch\\n\\n\\nclass KeyPointClassifier:\\n    def __init__(self, model_path=\\'./data/keypoint_classifier_2.pt\\'):\\n        # Load the PyTorch model\\n        self.model = torch.jit.load(model_path)\\n        self.model.eval()  # Set the model to evaluation mode\\n\\n    def __call__(self, landmark_list):\\n        # Convert the input landmark list to a PyTorch tensor\\n        input_tensor = torch.tensor([landmark_list], dtype=torch.float32)\\n\\n        # Perform inference\\n        with torch.no_grad():\\n            output = self.model(input_tensor)\\n\\n        # Get the predicted class index\\n        result_index = torch.argmax(output, dim=1).item()\\n        return result_index\\n\\ndef main():\\n    cap_device = 0\\n    cap_width = 960\\n    cap_height = 540\\n\\n    use_brect = True\\n\\n    cap = cv.VideoCapture(cap_device)\\n    cap.set(cv.CAP_PROP_FRAME_WIDTH, cap_width)\\n    cap.set(cv.CAP_PROP_FRAME_HEIGHT, cap_height)\\n\\n    mp_hands = mp.solutions.hands\\n    hands = mp_hands.Hands(\\n        model_complexity=0,\\n        static_image_mode=True,\\n        max_num_hands=2,\\n        min_detection_confidence=0.5,\\n        min_tracking_confidence=0.7\\n    )\\n\\n    keypoint_classifier = KeyPointClassifier()\\n\\n    with open(\\'./data/keypoint_classifier_labels.csv\\', encoding=\\'utf-8-sig\\') as f:\\n        keypoint_classifier_labels = csv.reader(f)\\n        keypoint_classifier_labels = [row[0] for row in keypoint_classifier_labels]\\n\\n    mode = 0\\n\\n    while True:\\n        key = cv.waitKey(10)\\n        if key == 27:\\n            break\\n        if key != -1:\\n            print()\\n        number, mode = select_mode(key, mode)\\n\\n        ret, image = cap.read()\\n        if not ret:\\n            break\\n        image = cv.flip(image, 1)\\n        debug_image = copy.deepcopy(image)\\n\\n        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\\n        image.flags.writeable = False\\n        results = hands.process(image)\\n        image.flags.writeable = True\\n\\n        if results.multi_hand_landmarks is not None:\\n            for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\\n                brect = calc_bounding_rect(debug_image, hand_landmarks)\\n                landmark_list = calc_landmark_list(debug_image, hand_landmarks)\\n\\n                # Calculate hand direction\\n                hand_direction = calculate_hand_direction(landmark_list)\\n\\n                pre_processed_landmark_list = pre_process_landmark(landmark_list)\\n\\n                logging_csv(number, mode, pre_processed_landmark_list)\\n\\n                hand_sign_id = keypoint_classifier(pre_processed_landmark_list)\\n\\n                debug_image = draw_bounding_rect(use_brect, debug_image, brect)\\n                debug_image = draw_landmarks(debug_image, landmark_list)\\n                debug_image = draw_info_text(\\n                    debug_image,\\n                    brect,\\n                    handedness,\\n                    f\"{keypoint_classifier_labels[hand_sign_id]}\",\\n                    f\"Direction: ({hand_direction[0]:.2f}, {hand_direction[1]:.2f})\"\\n                )\\n\\n        debug_image = draw_info(debug_image, mode, number)\\n\\n        cv.imshow(\\'Hand Gesture Recognition\\', debug_image)\\n\\n    cap.release()\\n    cv.destroyAllWindows()\\n\\ndef calculate_hand_direction(landmark_list):\\n    \"\"\"\\n    Calculate the direction vector of the hand based on the wrist and middle fingertip.\\n    Args:\\n        landmark_list: List of landmarks (x, y coordinates).\\n    Returns:\\n        A tuple representing the normalized direction vector (dx, dy).\\n    \"\"\"\\n    # Ensure landmark_list is structured as [[x1, y1], [x2, y2], ...]\\n    if isinstance(landmark_list[0], (int, float)):  # Flattened list\\n        landmark_list = [landmark_list[i:i + 2] for i in range(0, len(landmark_list), 2)]\\n\\n    # Wrist (landmark 0) and middle fingertip (landmark 12)\\n    wrist = np.array(landmark_list[0])\\n    middle_fingertip = np.array(landmark_list[12])\\n\\n    # Calculate the direction vector\\n    direction_vector = middle_fingertip - wrist\\n\\n    # Normalize the vector\\n    norm = np.linalg.norm(direction_vector)\\n    if norm == 0:\\n        return (0, 0)  # Avoid division by zero\\n    normalized_vector = direction_vector / norm\\n\\n    return tuple(normalized_vector)\\n\\ndef logging_csv(number, mode, landmark_list):\\n    \"\"\"\\n    Logs the selected number, landmark list, and hand direction to a CSV file if mode is 1.\\n    Also logs a horizontally mirrored version of the landmarks and introduces variance.\\n    \"\"\"\\n    if mode == 0:\\n        # Mode 0: No logging\\n        pass\\n    elif mode == 1 and (0 <= number <= 25):  # Ensure number corresponds to A-Z (0-25)\\n        csv_path = \\'./data/keypoint_dir.csv\\'\\n        try:\\n            # Ensure landmark_list is structured as [[x1, y1], [x2, y2], ...]\\n            if isinstance(landmark_list[0], (int, float)):  # Flattened list\\n                landmark_list = [landmark_list[i:i + 2] for i in range(0, len(landmark_list), 2)]\\n\\n            with open(csv_path, \\'a\\', newline=\"\") as f:\\n                writer = csv.writer(f)\\n\\n                # Calculate hand direction\\n                hand_direction = calculate_hand_direction(landmark_list)\\n\\n                # Flatten landmark_list for logging\\n                flattened_landmark_list = [coord for point in landmark_list for coord in point]\\n\\n                # Log the original data with hand direction\\n                writer.writerow([chr(number + 97), *flattened_landmark_list, *hand_direction])\\n\\n                # Create and log the mirrored data with hand direction\\n                mirrored_landmark_list = mirror_landmarks(flattened_landmark_list)\\n                mirrored_hand_direction = (-hand_direction[0], hand_direction[1])  # Flip x-direction\\n                writer.writerow([chr(number + 97), *mirrored_landmark_list, *mirrored_hand_direction])\\n\\n                # Add variance to the original data and log it with hand direction\\n                varied_landmark_list = add_variance(flattened_landmark_list)\\n                writer.writerow([chr(number + 97), *varied_landmark_list, *hand_direction])\\n\\n                # Add variance to the mirrored data and log it with hand direction\\n                varied_mirrored_landmark_list = add_variance(mirrored_landmark_list)\\n                writer.writerow([chr(number + 97), *varied_mirrored_landmark_list, *mirrored_hand_direction])\\n        except FileNotFoundError:\\n            print(f\"Error: CSV path \\'{csv_path}\\' not found.\")\\n        except Exception as e:\\n            print(f\"Error while logging to CSV: {e}\")\\n    return\\n\\n\\ndef mirror_landmarks(landmark_list):\\n    mirrored_landmark_list = []\\n    for i in range(0, len(landmark_list), 2):\\n        x = landmark_list[i]\\n        y = landmark_list[i + 1]\\n        mirrored_x = -x\\n        mirrored_landmark_list.extend([mirrored_x, y])\\n    return mirrored_landmark_list\\n\\n\\ndef add_variance(landmark_list, variance=0.02):\\n    varied_landmark_list = []\\n    for coord in landmark_list:\\n        varied_coord = coord + random.uniform(-variance, variance)\\n        varied_landmark_list.append(varied_coord)\\n    return varied_landmark_list\\n\\n\\ndef select_mode(key, mode):\\n    number = -1\\n    if ord(\\'a\\') <= key <= ord(\\'z\\'):\\n        number = key - 97\\n    elif key == ord(\\'0\\'):\\n        mode = 0\\n    elif key == ord(\\'1\\'):\\n        mode = 1\\n    return number, mode\\n\\n\\ndef pre_process_landmark(landmark_list):\\n    temp_landmark_list = copy.deepcopy(landmark_list)\\n\\n    # Convert to relative coordinates\\n    base_x, base_y = 0, 0\\n    for index, landmark_point in enumerate(temp_landmark_list):\\n        if index == 0:\\n            base_x, base_y = landmark_point[0], landmark_point[1]\\n        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\\n        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\\n\\n    # Convert to a one-dimensional list\\n    temp_landmark_list = list(itertools.chain.from_iterable(temp_landmark_list))\\n\\n    # Normalization\\n    max_value = max(list(map(abs, temp_landmark_list)))\\n\\n    def normalize_(n):\\n        return n / max_value\\n\\n    temp_landmark_list = list(map(normalize_, temp_landmark_list))\\n\\n    return temp_landmark_list\\n\\n\\ndef draw_landmarks(image, landmark_point):\\n    def draw_line_pair(p1, p2):\\n        cv.line(image, tuple(p1), tuple(p2), (0, 0, 0), 6)\\n        cv.line(image, tuple(p1), tuple(p2), (255, 255, 255), 2)\\n\\n    def draw_keypoint(pt, radius):\\n        cv.circle(image, tuple(pt), radius, (255, 255, 255), -1)\\n        cv.circle(image, tuple(pt), radius, (0, 0, 0), 1)\\n\\n    if len(landmark_point) > 0:\\n        finger_connections = [\\n            [2, 3, 4],\\n            [5, 6, 7, 8],\\n            [9, 10, 11, 12],\\n            [13, 14, 15, 16],\\n            [17, 18, 19, 20]\\n        ]\\n        for finger in finger_connections:\\n            for i in range(len(finger) - 1):\\n                draw_line_pair(landmark_point[finger[i]], landmark_point[finger[i + 1]])\\n        palm_connections = [\\n            (0, 1), (1, 2), (2, 5), (5, 9),\\n            (9, 13), (13, 17), (17, 0)\\n        ]\\n        for start, end in palm_connections:\\n            draw_line_pair(landmark_point[start], landmark_point[end])\\n    for index, landmark in enumerate(landmark_point):\\n        if index in [4, 8, 12, 16, 20]:\\n            draw_keypoint(landmark, 8)\\n        else:\\n            draw_keypoint(landmark, 5)\\n    return image\\n\\n\\ndef draw_bounding_rect(use_brect, image, brect):\\n    if use_brect:\\n        cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]), (0, 0, 0), 1)\\n    return image\\n\\n\\ndef draw_info_text(image, brect, handedness, hand_sign_text, finger_gesture_text):\\n    cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[1] - 44), (0, 0, 0), -1)\\n    info_text = handedness.classification[0].label[0:]\\n    if hand_sign_text != \"\":\\n        info_text = info_text + \\':\\' + hand_sign_text\\n    cv.putText(image, info_text, (brect[0] + 5, brect[1] - 26),\\n               cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv.LINE_AA)\\n    if finger_gesture_text != \"\":\\n        cv.putText(image, finger_gesture_text, (brect[0] + 5, brect[1] - 4),\\n                   cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv.LINE_AA)\\n    return image\\n\\n\\ndef calc_bounding_rect(image, landmarks):\\n    image_width, image_height = image.shape[1], image.shape[0]\\n    landmark_array = np.empty((0, 2), int)\\n    for _, landmark in enumerate(landmarks.landmark):\\n        landmark_x = min(int(landmark.x * image_width), image_width - 1)\\n        landmark_y = min(int(landmark.y * image_height), image_height - 1)\\n        landmark_point = [np.array((landmark_x, landmark_y))]\\n        landmark_array = np.append(landmark_array, landmark_point, axis=0)\\n    x, y, w, h = cv.boundingRect(landmark_array)\\n    return [x, y, x + w, y + h]\\n\\n\\ndef calc_landmark_list(image, landmarks):\\n    image_width, image_height = image.shape[1], image.shape[0]\\n    landmark_point = []\\n    for _, landmark in enumerate(landmarks.landmark):\\n        landmark_x = min(int(landmark.x * image_width), image_width - 1)\\n        landmark_y = min(int(landmark.y * image_height), image_height - 1)\\n        landmark_point.append([landmark_x, landmark_y])\\n    return landmark_point\\n\\n\\ndef draw_info(image, mode, number):\\n    mode_string = [\\'Logging Key Point\\', \\'Not Logging\\']\\n    if 1 <= mode <= 2:\\n        cv.putText(image, \"MODE: \" + mode_string[mode - 1], (10, 90),\\n                   cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\\n                   cv.LINE_AA)\\n        if number == -1:\\n            pass\\n        elif 0 <= number <= 25:\\n            cv.putText(image, \"LETTER: \" + str(chr(number + 97)), (10, 110),\\n                       cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\\n                       cv.LINE_AA)\\n    return image\\n\\n\\nif __name__ == \\'__main__\\':\\n    main()'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import csv\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import torch\n",
    "\n",
    "\n",
    "class KeyPointClassifier:\n",
    "    def __init__(self, model_path='./data/keypoint_classifier_2.pt'):\n",
    "        # Load the PyTorch model\n",
    "        self.model = torch.jit.load(model_path)\n",
    "        self.model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    def __call__(self, landmark_list):\n",
    "        # Convert the input landmark list to a PyTorch tensor\n",
    "        input_tensor = torch.tensor([landmark_list], dtype=torch.float32)\n",
    "\n",
    "        # Perform inference\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_tensor)\n",
    "\n",
    "        # Get the predicted class index\n",
    "        result_index = torch.argmax(output, dim=1).item()\n",
    "        return result_index\n",
    "\n",
    "def main():\n",
    "    cap_device = 0\n",
    "    cap_width = 960\n",
    "    cap_height = 540\n",
    "\n",
    "    use_brect = True\n",
    "\n",
    "    cap = cv.VideoCapture(cap_device)\n",
    "    cap.set(cv.CAP_PROP_FRAME_WIDTH, cap_width)\n",
    "    cap.set(cv.CAP_PROP_FRAME_HEIGHT, cap_height)\n",
    "\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(\n",
    "        model_complexity=0,\n",
    "        static_image_mode=True,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.7\n",
    "    )\n",
    "\n",
    "    keypoint_classifier = KeyPointClassifier()\n",
    "\n",
    "    with open('./data/keypoint_classifier_labels.csv', encoding='utf-8-sig') as f:\n",
    "        keypoint_classifier_labels = csv.reader(f)\n",
    "        keypoint_classifier_labels = [row[0] for row in keypoint_classifier_labels]\n",
    "\n",
    "    mode = 0\n",
    "\n",
    "    while True:\n",
    "        key = cv.waitKey(10)\n",
    "        if key == 27:\n",
    "            break\n",
    "        if key != -1:\n",
    "            print()\n",
    "        number, mode = select_mode(key, mode)\n",
    "\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        image = cv.flip(image, 1)\n",
    "        debug_image = copy.deepcopy(image)\n",
    "\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        if results.multi_hand_landmarks is not None:\n",
    "            for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "                brect = calc_bounding_rect(debug_image, hand_landmarks)\n",
    "                landmark_list = calc_landmark_list(debug_image, hand_landmarks)\n",
    "\n",
    "                # Calculate hand direction\n",
    "                hand_direction = calculate_hand_direction(landmark_list)\n",
    "\n",
    "                pre_processed_landmark_list = pre_process_landmark(landmark_list)\n",
    "\n",
    "                logging_csv(number, mode, pre_processed_landmark_list)\n",
    "\n",
    "                hand_sign_id = keypoint_classifier(pre_processed_landmark_list)\n",
    "\n",
    "                debug_image = draw_bounding_rect(use_brect, debug_image, brect)\n",
    "                debug_image = draw_landmarks(debug_image, landmark_list)\n",
    "                debug_image = draw_info_text(\n",
    "                    debug_image,\n",
    "                    brect,\n",
    "                    handedness,\n",
    "                    f\"{keypoint_classifier_labels[hand_sign_id]}\",\n",
    "                    f\"Direction: ({hand_direction[0]:.2f}, {hand_direction[1]:.2f})\"\n",
    "                )\n",
    "\n",
    "        debug_image = draw_info(debug_image, mode, number)\n",
    "\n",
    "        cv.imshow('Hand Gesture Recognition', debug_image)\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "def calculate_hand_direction(landmark_list):\n",
    "    \"\"\"\n",
    "    Calculate the direction vector of the hand based on the wrist and middle fingertip.\n",
    "    Args:\n",
    "        landmark_list: List of landmarks (x, y coordinates).\n",
    "    Returns:\n",
    "        A tuple representing the normalized direction vector (dx, dy).\n",
    "    \"\"\"\n",
    "    # Ensure landmark_list is structured as [[x1, y1], [x2, y2], ...]\n",
    "    if isinstance(landmark_list[0], (int, float)):  # Flattened list\n",
    "        landmark_list = [landmark_list[i:i + 2] for i in range(0, len(landmark_list), 2)]\n",
    "\n",
    "    # Wrist (landmark 0) and middle fingertip (landmark 12)\n",
    "    wrist = np.array(landmark_list[0])\n",
    "    middle_fingertip = np.array(landmark_list[12])\n",
    "\n",
    "    # Calculate the direction vector\n",
    "    direction_vector = middle_fingertip - wrist\n",
    "\n",
    "    # Normalize the vector\n",
    "    norm = np.linalg.norm(direction_vector)\n",
    "    if norm == 0:\n",
    "        return (0, 0)  # Avoid division by zero\n",
    "    normalized_vector = direction_vector / norm\n",
    "\n",
    "    return tuple(normalized_vector)\n",
    "\n",
    "def logging_csv(number, mode, landmark_list):\n",
    "    \"\"\"\n",
    "    Logs the selected number, landmark list, and hand direction to a CSV file if mode is 1.\n",
    "    Also logs a horizontally mirrored version of the landmarks and introduces variance.\n",
    "    \"\"\"\n",
    "    if mode == 0:\n",
    "        # Mode 0: No logging\n",
    "        pass\n",
    "    elif mode == 1 and (0 <= number <= 25):  # Ensure number corresponds to A-Z (0-25)\n",
    "        csv_path = './data/keypoint_dir.csv'\n",
    "        try:\n",
    "            # Ensure landmark_list is structured as [[x1, y1], [x2, y2], ...]\n",
    "            if isinstance(landmark_list[0], (int, float)):  # Flattened list\n",
    "                landmark_list = [landmark_list[i:i + 2] for i in range(0, len(landmark_list), 2)]\n",
    "\n",
    "            with open(csv_path, 'a', newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "\n",
    "                # Calculate hand direction\n",
    "                hand_direction = calculate_hand_direction(landmark_list)\n",
    "\n",
    "                # Flatten landmark_list for logging\n",
    "                flattened_landmark_list = [coord for point in landmark_list for coord in point]\n",
    "\n",
    "                # Log the original data with hand direction\n",
    "                writer.writerow([chr(number + 97), *flattened_landmark_list, *hand_direction])\n",
    "\n",
    "                # Create and log the mirrored data with hand direction\n",
    "                mirrored_landmark_list = mirror_landmarks(flattened_landmark_list)\n",
    "                mirrored_hand_direction = (-hand_direction[0], hand_direction[1])  # Flip x-direction\n",
    "                writer.writerow([chr(number + 97), *mirrored_landmark_list, *mirrored_hand_direction])\n",
    "\n",
    "                # Add variance to the original data and log it with hand direction\n",
    "                varied_landmark_list = add_variance(flattened_landmark_list)\n",
    "                writer.writerow([chr(number + 97), *varied_landmark_list, *hand_direction])\n",
    "\n",
    "                # Add variance to the mirrored data and log it with hand direction\n",
    "                varied_mirrored_landmark_list = add_variance(mirrored_landmark_list)\n",
    "                writer.writerow([chr(number + 97), *varied_mirrored_landmark_list, *mirrored_hand_direction])\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: CSV path '{csv_path}' not found.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while logging to CSV: {e}\")\n",
    "    return\n",
    "\n",
    "\n",
    "def mirror_landmarks(landmark_list):\n",
    "    mirrored_landmark_list = []\n",
    "    for i in range(0, len(landmark_list), 2):\n",
    "        x = landmark_list[i]\n",
    "        y = landmark_list[i + 1]\n",
    "        mirrored_x = -x\n",
    "        mirrored_landmark_list.extend([mirrored_x, y])\n",
    "    return mirrored_landmark_list\n",
    "\n",
    "\n",
    "def add_variance(landmark_list, variance=0.02):\n",
    "    varied_landmark_list = []\n",
    "    for coord in landmark_list:\n",
    "        varied_coord = coord + random.uniform(-variance, variance)\n",
    "        varied_landmark_list.append(varied_coord)\n",
    "    return varied_landmark_list\n",
    "\n",
    "\n",
    "def select_mode(key, mode):\n",
    "    number = -1\n",
    "    if ord('a') <= key <= ord('z'):\n",
    "        number = key - 97\n",
    "    elif key == ord('0'):\n",
    "        mode = 0\n",
    "    elif key == ord('1'):\n",
    "        mode = 1\n",
    "    return number, mode\n",
    "\n",
    "\n",
    "def pre_process_landmark(landmark_list):\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_landmark_list = list(itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    # Normalization\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / max_value\n",
    "\n",
    "    temp_landmark_list = list(map(normalize_, temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list\n",
    "\n",
    "\n",
    "def draw_landmarks(image, landmark_point):\n",
    "    def draw_line_pair(p1, p2):\n",
    "        cv.line(image, tuple(p1), tuple(p2), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(p1), tuple(p2), (255, 255, 255), 2)\n",
    "\n",
    "    def draw_keypoint(pt, radius):\n",
    "        cv.circle(image, tuple(pt), radius, (255, 255, 255), -1)\n",
    "        cv.circle(image, tuple(pt), radius, (0, 0, 0), 1)\n",
    "\n",
    "    if len(landmark_point) > 0:\n",
    "        finger_connections = [\n",
    "            [2, 3, 4],\n",
    "            [5, 6, 7, 8],\n",
    "            [9, 10, 11, 12],\n",
    "            [13, 14, 15, 16],\n",
    "            [17, 18, 19, 20]\n",
    "        ]\n",
    "        for finger in finger_connections:\n",
    "            for i in range(len(finger) - 1):\n",
    "                draw_line_pair(landmark_point[finger[i]], landmark_point[finger[i + 1]])\n",
    "        palm_connections = [\n",
    "            (0, 1), (1, 2), (2, 5), (5, 9),\n",
    "            (9, 13), (13, 17), (17, 0)\n",
    "        ]\n",
    "        for start, end in palm_connections:\n",
    "            draw_line_pair(landmark_point[start], landmark_point[end])\n",
    "    for index, landmark in enumerate(landmark_point):\n",
    "        if index in [4, 8, 12, 16, 20]:\n",
    "            draw_keypoint(landmark, 8)\n",
    "        else:\n",
    "            draw_keypoint(landmark, 5)\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_bounding_rect(use_brect, image, brect):\n",
    "    if use_brect:\n",
    "        cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]), (0, 0, 0), 1)\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_info_text(image, brect, handedness, hand_sign_text, finger_gesture_text):\n",
    "    cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[1] - 44), (0, 0, 0), -1)\n",
    "    info_text = handedness.classification[0].label[0:]\n",
    "    if hand_sign_text != \"\":\n",
    "        info_text = info_text + ':' + hand_sign_text\n",
    "    cv.putText(image, info_text, (brect[0] + 5, brect[1] - 26),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv.LINE_AA)\n",
    "    if finger_gesture_text != \"\":\n",
    "        cv.putText(image, finger_gesture_text, (brect[0] + 5, brect[1] - 4),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv.LINE_AA)\n",
    "    return image\n",
    "\n",
    "\n",
    "def calc_bounding_rect(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "    landmark_array = np.empty((0, 2), int)\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        landmark_point = [np.array((landmark_x, landmark_y))]\n",
    "        landmark_array = np.append(landmark_array, landmark_point, axis=0)\n",
    "    x, y, w, h = cv.boundingRect(landmark_array)\n",
    "    return [x, y, x + w, y + h]\n",
    "\n",
    "\n",
    "def calc_landmark_list(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "    landmark_point = []\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "    return landmark_point\n",
    "\n",
    "\n",
    "def draw_info(image, mode, number):\n",
    "    mode_string = ['Logging Key Point', 'Not Logging']\n",
    "    if 1 <= mode <= 2:\n",
    "        cv.putText(image, \"MODE: \" + mode_string[mode - 1], (10, 90),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                   cv.LINE_AA)\n",
    "        if number == -1:\n",
    "            pass\n",
    "        elif 0 <= number <= 25:\n",
    "            cv.putText(image, \"LETTER: \" + str(chr(number + 97)), (10, 110),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                       cv.LINE_AA)\n",
    "    return image\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML_CompVis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
