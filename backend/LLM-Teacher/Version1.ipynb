{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ibm_watsonx_ai import Credentials, APIClient\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from ibm_watsonx_ai.foundation_models.schema import TextGenParameters\n",
    "from decouple import Config, RepositoryEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables using python-decouple\n",
    "# The .env file should be in the root of the project\n",
    "# The .env file should NOT be committed to the repository\n",
    "\n",
    "config = Config(RepositoryEnv(\".env.paul\"))\n",
    "\n",
    "# Load the credentials\n",
    "WX_API_KEY = config(\"WX_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = Credentials(\n",
    "    url = \"https://us-south.ml.cloud.ibm.com\",\n",
    "    api_key = WX_API_KEY\n",
    ")\n",
    "client = APIClient(\n",
    "    credentials=credentials, \n",
    "    project_id=\"68126b74-155e-4a70-aa2c-1781dfad87f6\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': 'ibm/granite-13b-instruct-v2',\n",
       " 'created_at': '2025-04-28T15:05:50.941Z',\n",
       " 'results': [{'generated_text': \"I'm so excited to be here!\",\n",
       "   'generated_token_count': 9,\n",
       "   'input_token_count': 6,\n",
       "   'stop_reason': 'eos_token'}],\n",
       " 'system': {'warnings': [{'message': \"The value of 'parameters.max_new_tokens' for this model was set to value 20\",\n",
       "    'id': 'unspecified_max_new_tokens',\n",
       "    'additional_properties': {'limit': 0,\n",
       "     'new_value': 20,\n",
       "     'parameter': 'parameters.max_new_tokens',\n",
       "     'value': 0}}]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelInference(\n",
    "    api_client=client,\n",
    "    model_id=\"ibm/granite-13b-instruct-v2\",\n",
    ")\n",
    "prompt = \"Hello from copenhagen!\"\n",
    "generated_response = model.generate(prompt)\n",
    "\n",
    "generated_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test = {\n",
    "    \"Llama-3-8b\": \"meta-llama/llama-3-8b-instruct\",\n",
    "    \"Granite-13b\": \"ibm/granite-13b-chat-v2\",\n",
    "    \"Granite-20b\": \"ibm/granite-20b-multilingual\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ZERO_SHOT_PROMPT = \"\"\"You are an ASL (American Sign Language) instructor.\n",
    "\n",
    "Your task is to describe how to perform the ASL sign for the following concept:\n",
    "\n",
    "SIGN:\n",
    "{sign_name}\n",
    "\n",
    "Please provide a clear, simple, and beginner-friendly description.\n",
    "\n",
    "Description:\n",
    "\"\"\"\n",
    "\n",
    "ONE_SHOT_PROMPT = \"\"\"You are an expert ASL (American Sign Language) instructor.\n",
    "\n",
    "Here is an example of a description:\n",
    "\n",
    "EXAMPLE:\n",
    "SIGN: Hello\n",
    "Description: Raise your hand near your forehead, palm facing outward, and move your hand away from your forehead in a small arc.\n",
    "\n",
    "Now, describe the following sign:\n",
    "\n",
    "SIGN:\n",
    "{sign_name}\n",
    "\n",
    "Please provide a clear, step-by-step description.\n",
    "\n",
    "Description:\n",
    "\"\"\"\n",
    "\n",
    "FEW_SHOT_PROMPT = \"\"\"You are an expert ASL (American Sign Language) instructor.\n",
    "\n",
    "Below are a few examples of how to describe ASL signs:\n",
    "\n",
    "EXAMPLE 1:\n",
    "SIGN: Hello\n",
    "Description: Raise your hand near your forehead, palm facing outward, and move your hand away from your forehead in a small arc.\n",
    "\n",
    "EXAMPLE 2:\n",
    "SIGN: Thank You\n",
    "Description: Place your fingertips near your chin and move your hand outward away from your face.\n",
    "\n",
    "EXAMPLE 3:\n",
    "SIGN: Apple\n",
    "Description: Make a fist with your hand and twist it near your cheek.\n",
    "\n",
    "Now, describe the following sign:\n",
    "\n",
    "SIGN:\n",
    "{sign_name}\n",
    "\n",
    "Please provide a clear, step-by-step description.\n",
    "\n",
    "Description:\n",
    "\"\"\"\n",
    "\n",
    "CHAIN_OF_THOUGHT_PROMPT = \"\"\"You are an ASL (American Sign Language) instructor.\n",
    "\n",
    "SIGN:\n",
    "{sign_name}\n",
    "\n",
    "Let's think step-by-step:\n",
    "1. Identify the correct handshape needed for this sign.\n",
    "2. Identify the correct palm orientation.\n",
    "3. Identify the correct location relative to the body.\n",
    "4. Identify the correct movement and motion path.\n",
    "5. Mention if facial expressions are needed.\n",
    "\n",
    "Explanation:\n",
    "\"\"\"\n",
    "\n",
    "CHAIN_OF_THOUGHT_APPEND = \"\"\"\n",
    "Based on the reasoning above, please now provide the full description:\n",
    "\n",
    "Description:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Prompting functions to insert sign_name dynamically\n",
    "\n",
    "def zero_shot_prompt(sign_name):\n",
    "    return ZERO_SHOT_PROMPT.format(sign_name=sign_name)\n",
    "\n",
    "def one_shot_prompt(sign_name):\n",
    "    return ONE_SHOT_PROMPT.format(sign_name=sign_name)\n",
    "\n",
    "def few_shot_prompt(sign_name):\n",
    "    return FEW_SHOT_PROMPT.format(sign_name=sign_name)\n",
    "\n",
    "def chain_of_thought_prompt(sign_name):\n",
    "    return CHAIN_OF_THOUGHT_PROMPT.format(sign_name=sign_name) + CHAIN_OF_THOUGHT_APPEND\n",
    "\n",
    "# Mapping of style name to function\n",
    "prompting_styles = {\n",
    "    \"Zero-Shot\": zero_shot_prompt,\n",
    "    \"One-Shot\": one_shot_prompt,\n",
    "    \"Few-Shot\": few_shot_prompt,\n",
    "    \"Chain-of-Thought\": chain_of_thought_prompt,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define which models to test\n",
    "models_to_test = {\n",
    "    \"Llama-3-8b\": \"meta-llama/llama-3-8b-instruct\",\n",
    "    \"Granite-13b\": \"ibm/granite-13b-chat-v2\",\n",
    "    \"Granite-20b\": \"ibm/granite-20b-multilingual\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Function to generate description using a model + prompt\n",
    "def generate_with_model_and_prompt(sign_name, model_id, prompt_function):\n",
    "    model = ModelInference(\n",
    "        model_id=model_id,\n",
    "        params=TextGenParameters(decoding_method=\"sample\", max_new_tokens=500),\n",
    "        client=client,\n",
    "    )\n",
    "    \n",
    "    prompt = prompt_function(sign_name)\n",
    "    \n",
    "    response = model.generate(prompt=prompt)\n",
    "    \n",
    "    return response.get('results')[0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.A: Define the Judge Prompt Template\n",
    "\n",
    "JUDGE_PROMPT_TEMPLATE = \"\"\"You are an expert American Sign Language (ASL) instructor.\n",
    "\n",
    "Evaluate the following generated description for the ASL sign '{sign_name}':\n",
    "\n",
    "\\\"\\\"\\\" \n",
    "{generated_description}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Assess it based on:\n",
    "- Accuracy (correct description of handshape, movement, facial expression)\n",
    "- Clarity (easy to understand for beginners)\n",
    "- Completeness (no important details missing)\n",
    "\n",
    "Provide:\n",
    "1. A score from 1 to 10\n",
    "2. A short justification.\n",
    "\n",
    "Format your response like this:\n",
    "\n",
    "Score: <number>/10\n",
    "Justification: <your explanation>\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.B: Judge function uses the template dynamically\n",
    "\n",
    "def evaluate_with_judge(sign_name, generated_description):\n",
    "    evaluation_prompt = JUDGE_PROMPT_TEMPLATE.format(\n",
    "        sign_name=sign_name,\n",
    "        generated_description=generated_description\n",
    "    )\n",
    "    \n",
    "    response = judge_model.generate(prompt=evaluation_prompt)\n",
    "    judged_text = response.get('results')[0]['generated_text']\n",
    "    \n",
    "    return judged_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Run full comparison across models and prompts\n",
    "def run_full_comparison_with_judging(sign_name):\n",
    "    results = []\n",
    "\n",
    "    for model_name, model_id in models_to_test.items():\n",
    "        for prompt_name, prompt_func in prompting_styles.items():\n",
    "            try:\n",
    "                # Generate the description\n",
    "                description = generate_with_model_and_prompt(sign_name, model_id, prompt_func)\n",
    "                \n",
    "                # Evaluate the description\n",
    "                judge_feedback = evaluate_with_judge(sign_name, description)\n",
    "                \n",
    "                # Store all results\n",
    "                results.append({\n",
    "                    \"Model\": model_name,\n",
    "                    \"Prompt Style\": prompt_name,\n",
    "                    \"Sign\": sign_name,\n",
    "                    \"Description\": description,\n",
    "                    \"Judge Feedback\": judge_feedback\n",
    "                })\n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    \"Model\": model_name,\n",
    "                    \"Prompt Style\": prompt_name,\n",
    "                    \"Sign\": sign_name,\n",
    "                    \"Description\": f\"Error: {e}\",\n",
    "                    \"Judge Feedback\": \"N/A\"\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Input from user and run\n",
    "if __name__ == \"__main__\":\n",
    "    sign_to_test = input(\"Enter the ASL sign you want to explore: \")\n",
    "    \n",
    "    comparison_df = run_full_comparison_with_judging(sign_to_test)\n",
    "\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(comparison_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml25-ma2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
