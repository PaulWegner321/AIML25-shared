{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ibm_watsonx_ai import Credentials, APIClient\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from ibm_watsonx_ai.foundation_models.schema import TextGenParameters\n",
    "from decouple import Config, RepositoryEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables using python-decouple\n",
    "# The .env file should be in the root of the project\n",
    "# The .env file should NOT be committed to the repository\n",
    "\n",
    "config = Config(RepositoryEnv(\".env.paul\"))\n",
    "\n",
    "# Load the credentials\n",
    "WX_API_KEY = config(\"WX_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = Credentials(\n",
    "    url = \"https://us-south.ml.cloud.ibm.com\",\n",
    "    api_key = WX_API_KEY\n",
    ")\n",
    "client = APIClient(\n",
    "    credentials=credentials, \n",
    "    project_id=\"68126b74-155e-4a70-aa2c-1781dfad87f6\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': 'ibm/granite-13b-instruct-v2',\n",
       " 'created_at': '2025-04-28T20:23:19.759Z',\n",
       " 'results': [{'generated_text': \"I'm so excited to be here!\",\n",
       "   'generated_token_count': 9,\n",
       "   'input_token_count': 6,\n",
       "   'stop_reason': 'eos_token',\n",
       "   'seed': 2640387947}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Setup the Model (Granite-13b-chat-v2) ---\n",
    "params = TextGenParameters(\n",
    "    temperature=0.2,            # Light creativity\n",
    "    max_new_tokens=300          # Enough for descriptive text\n",
    ")\n",
    "\n",
    "model = ModelInference(\n",
    "    api_client=client,\n",
    "    params=params,\n",
    "    model_id=\"ibm/granite-13b-instruct-v2\",\n",
    ")\n",
    "prompt = \"Hello from copenhagen!\"\n",
    "generated_response = model.generate(prompt)\n",
    "\n",
    "generated_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(sign_name: str) -> str:\n",
    "    return (\n",
    "        f\"You are an American Sign Language (ASL) expert.\\n\\n\"\n",
    "        f\"Please clearly explain how to perform the ASL sign for the concept '{sign_name}'. \"\n",
    "        f\"Describe the hand shape, palm orientation, movement, location, and any facial expression needed.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate ASL Description ---\n",
    "def generate_asl_description(sign_name: str) -> str:\n",
    "    prompt = create_prompt(sign_name)\n",
    "    \n",
    "    response = model.generate(prompt=prompt)\n",
    "    generated_text = response['results'][0]['generated_text']\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëã Welcome to the ASL Sign Generator using Granite-13b!\n",
      "\n",
      "‚úÖ Generated ASL Description:\n",
      "\n",
      "The sign for 'tree' is made by moving the index finger and thumb in a circular motion. The hand is held with the palm facing upwards. \n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    sign_to_explain = input(\"üìù Enter the ASL sign you want explained: \")\n",
    "\n",
    "    try:\n",
    "        description = generate_asl_description(sign_to_explain)\n",
    "        print(\"\\n‚úÖ Generated ASL Description:\\n\")\n",
    "        print(description)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during generation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_judge_prompt(sign_name: str, description: str) -> str:\n",
    "    return (\n",
    "        f\"You are an ASL (American Sign Language) expert evaluator.\\n\\n\"\n",
    "        f\"Evaluate the following description for the ASL sign '{sign_name}':\\n\\n\"\n",
    "        f\"---\\n{description}\\n---\\n\\n\"\n",
    "        f\"Return ONLY a JSON object like this (no extra text):\\n\\n\"\n",
    "        f\"{{\\n\"\n",
    "        f\"  \\\"accuracy\\\": <0 or 1>,\\n\"\n",
    "        f\"  \\\"fluffiness\\\": <0-10>\\n\"\n",
    "        f\"}}\\n\\n\"\n",
    "        f\"IMPORTANT: Respond ONLY with the JSON. No explanations, no extra text.\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_description(sign_name: str, description: str) -> dict:\n",
    "    judge_prompt = create_judge_prompt(sign_name, description)\n",
    "\n",
    "    # Use same model to judge\n",
    "    response = model.generate(prompt=judge_prompt)\n",
    "    judged_text = response['results'][0]['generated_text']\n",
    "\n",
    "    try:\n",
    "        # Safely parse JSON result\n",
    "        import json\n",
    "        judge_result = json.loads(judged_text)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not parse judge response: {e}\")\n",
    "        judge_result = {\"accuracy\": None, \"fluffiness\": None}\n",
    "\n",
    "    return judge_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëã Welcome to the ASL Sign Generator using Granite-13b!\n",
      "\n",
      "‚úÖ Generated ASL Description:\n",
      "\n",
      "Hello is signed by making a flat hand into a 'C' shape with the middle finger sticking up. The hand is held flat in front of the mouth with the palm facing forward. Hello is signed with the eyes looking forward and the mouth closed. \n",
      "\n",
      "üìä Evaluation Result:\n",
      "\n",
      "{'accuracy': 0.9, 'fluffiness': 0}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"üëã Welcome to the ASL Sign Generator using Granite-13b!\")\n",
    "    sign_to_explain = input(\"üìù Enter the ASL sign you want explained: \")\n",
    "\n",
    "    try:\n",
    "        # Generate ASL description\n",
    "        description = generate_asl_description(sign_to_explain)\n",
    "        print(\"\\n‚úÖ Generated ASL Description:\\n\")\n",
    "        print(description)\n",
    "\n",
    "        # Judge the description\n",
    "        judge_result = evaluate_description(sign_to_explain, description)\n",
    "        print(\"\\nüìä Evaluation Result:\\n\")\n",
    "        print(judge_result)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during generation or evaluation: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test = {\n",
    "    \"Llama-3-8b\": \"meta-llama/llama-3-8b-instruct\",\n",
    "    \"Granite-13b\": \"ibm/granite-13b-chat-v2\",\n",
    "    \"Granite-20b\": \"ibm/granite-20b-multilingual\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ZERO_SHOT_PROMPT = \"\"\"You are an ASL (American Sign Language) instructor.\n",
    "\n",
    "Your task is to describe how to perform the ASL sign for the following concept:\n",
    "\n",
    "SIGN:\n",
    "{sign_name}\n",
    "\n",
    "Please provide a clear, simple, and beginner-friendly description.\n",
    "\n",
    "Description:\n",
    "\"\"\"\n",
    "\n",
    "ONE_SHOT_PROMPT = \"\"\"You are an expert ASL (American Sign Language) instructor.\n",
    "\n",
    "Here is an example of a description:\n",
    "\n",
    "EXAMPLE:\n",
    "SIGN: Hello\n",
    "Description: Raise your hand near your forehead, palm facing outward, and move your hand away from your forehead in a small arc.\n",
    "\n",
    "Now, describe the following sign:\n",
    "\n",
    "SIGN:\n",
    "{sign_name}\n",
    "\n",
    "Please provide a clear, step-by-step description.\n",
    "\n",
    "Description:\n",
    "\"\"\"\n",
    "\n",
    "FEW_SHOT_PROMPT = \"\"\"You are an expert ASL (American Sign Language) instructor.\n",
    "\n",
    "Below are a few examples of how to describe ASL signs:\n",
    "\n",
    "EXAMPLE 1:\n",
    "SIGN: Hello\n",
    "Description: Raise your hand near your forehead, palm facing outward, and move your hand away from your forehead in a small arc.\n",
    "\n",
    "EXAMPLE 2:\n",
    "SIGN: Thank You\n",
    "Description: Place your fingertips near your chin and move your hand outward away from your face.\n",
    "\n",
    "EXAMPLE 3:\n",
    "SIGN: Apple\n",
    "Description: Make a fist with your hand and twist it near your cheek.\n",
    "\n",
    "Now, describe the following sign:\n",
    "\n",
    "SIGN:\n",
    "{sign_name}\n",
    "\n",
    "Please provide a clear, step-by-step description.\n",
    "\n",
    "Description:\n",
    "\"\"\"\n",
    "\n",
    "CHAIN_OF_THOUGHT_PROMPT = \"\"\"You are an ASL (American Sign Language) instructor.\n",
    "\n",
    "SIGN:\n",
    "{sign_name}\n",
    "\n",
    "Let's think step-by-step:\n",
    "1. Identify the correct handshape needed for this sign.\n",
    "2. Identify the correct palm orientation.\n",
    "3. Identify the correct location relative to the body.\n",
    "4. Identify the correct movement and motion path.\n",
    "5. Mention if facial expressions are needed.\n",
    "\n",
    "Explanation:\n",
    "\"\"\"\n",
    "\n",
    "CHAIN_OF_THOUGHT_APPEND = \"\"\"\n",
    "Based on the reasoning above, please now provide the full description:\n",
    "\n",
    "Description:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Prompting functions to insert sign_name dynamically\n",
    "\n",
    "def zero_shot_prompt(sign_name):\n",
    "    return ZERO_SHOT_PROMPT.format(sign_name=sign_name)\n",
    "\n",
    "def one_shot_prompt(sign_name):\n",
    "    return ONE_SHOT_PROMPT.format(sign_name=sign_name)\n",
    "\n",
    "def few_shot_prompt(sign_name):\n",
    "    return FEW_SHOT_PROMPT.format(sign_name=sign_name)\n",
    "\n",
    "def chain_of_thought_prompt(sign_name):\n",
    "    return CHAIN_OF_THOUGHT_PROMPT.format(sign_name=sign_name) + CHAIN_OF_THOUGHT_APPEND\n",
    "\n",
    "# Mapping of style name to function\n",
    "prompting_styles = {\n",
    "    \"Zero-Shot\": zero_shot_prompt,\n",
    "    \"One-Shot\": one_shot_prompt,\n",
    "    \"Few-Shot\": few_shot_prompt,\n",
    "    \"Chain-of-Thought\": chain_of_thought_prompt,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define which models to test\n",
    "models_to_test = {\n",
    "    \"Llama-3-8b\": \"meta-llama/llama-3-8b-instruct\",\n",
    "    \"Granite-13b\": \"ibm/granite-13b-chat-v2\",\n",
    "    \"Granite-20b\": \"ibm/granite-20b-multilingual\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Function to generate description using a model + prompt\n",
    "def generate_with_model_and_prompt(sign_name, model_id, prompt_function):\n",
    "    model = ModelInference(\n",
    "        model_id=model_id,\n",
    "        params=TextGenParameters(decoding_method=\"sample\", max_new_tokens=500),\n",
    "        client=client,\n",
    "    )\n",
    "    \n",
    "    prompt = prompt_function(sign_name)\n",
    "    \n",
    "    response = model.generate(prompt=prompt)\n",
    "    \n",
    "    return response.get('results')[0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.A: Define the Judge Prompt Template\n",
    "\n",
    "JUDGE_PROMPT_TEMPLATE = \"\"\"You are an expert American Sign Language (ASL) instructor.\n",
    "\n",
    "Evaluate the following generated description for the ASL sign '{sign_name}':\n",
    "\n",
    "\\\"\\\"\\\" \n",
    "{generated_description}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Assess it based on:\n",
    "- Accuracy (correct description of handshape, movement, facial expression)\n",
    "- Clarity (easy to understand for beginners)\n",
    "- Completeness (no important details missing)\n",
    "\n",
    "Provide:\n",
    "1. A score from 1 to 10\n",
    "2. A short justification.\n",
    "\n",
    "Format your response like this:\n",
    "\n",
    "Score: <number>/10\n",
    "Justification: <your explanation>\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.B: Judge function uses the template dynamically\n",
    "\n",
    "def evaluate_with_judge(sign_name, generated_description):\n",
    "    evaluation_prompt = JUDGE_PROMPT_TEMPLATE.format(\n",
    "        sign_name=sign_name,\n",
    "        generated_description=generated_description\n",
    "    )\n",
    "    \n",
    "    response = judge_model.generate(prompt=evaluation_prompt)\n",
    "    judged_text = response.get('results')[0]['generated_text']\n",
    "    \n",
    "    return judged_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Run full comparison across models and prompts\n",
    "def run_full_comparison_with_judging(sign_name):\n",
    "    results = []\n",
    "\n",
    "    for model_name, model_id in models_to_test.items():\n",
    "        for prompt_name, prompt_func in prompting_styles.items():\n",
    "            try:\n",
    "                # Generate the description\n",
    "                description = generate_with_model_and_prompt(sign_name, model_id, prompt_func)\n",
    "                \n",
    "                # Evaluate the description\n",
    "                judge_feedback = evaluate_with_judge(sign_name, description)\n",
    "                \n",
    "                # Store all results\n",
    "                results.append({\n",
    "                    \"Model\": model_name,\n",
    "                    \"Prompt Style\": prompt_name,\n",
    "                    \"Sign\": sign_name,\n",
    "                    \"Description\": description,\n",
    "                    \"Judge Feedback\": judge_feedback\n",
    "                })\n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    \"Model\": model_name,\n",
    "                    \"Prompt Style\": prompt_name,\n",
    "                    \"Sign\": sign_name,\n",
    "                    \"Description\": f\"Error: {e}\",\n",
    "                    \"Judge Feedback\": \"N/A\"\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Input from user and run\n",
    "if __name__ == \"__main__\":\n",
    "    sign_to_test = input(\"Enter the ASL sign you want to explore: \")\n",
    "    \n",
    "    comparison_df = run_full_comparison_with_judging(sign_to_test)\n",
    "\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(comparison_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml25-ma2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
